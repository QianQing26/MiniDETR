# ğŸ§© Mini-DETR

> A lightweight and educational implementation of [DETR (End-to-End Object Detection with Transformers)](https://arxiv.org/abs/2005.12872) using PyTorch.  
> Designed for small GPU devices (â‰¤8GB), educational use, and clarity-first principles.

---

## âœ¨ Highlights

- âœ… Clean implementation with **no external detection libraries** (e.g. no HuggingFace, MMDetection)
- âœ… Fully working **training pipeline** (ResNet50 + Transformer)
- âœ… Built-in **Hungarian matching loss**
- âœ… Supports **learning rate warmup**, **backbone freezing**, **differential LR**
- âœ… Includes **mAP evaluation** using only PyTorch and NumPy
- âœ… Structure & code style inspired by open-source conventions

---

## ğŸ“‚ Project Structure

```
MiniDETR/
 â”œâ”€â”€ configs/              # (Optional) configs
 â”œâ”€â”€ data/                 # dataset JSON & transform
 â”‚   â”œâ”€â”€ voc_dataset.py
 â”‚   â”œâ”€â”€ transforms.py
 â”œâ”€â”€ models/               # model components
 â”‚   â”œâ”€â”€ detr.py
 â”‚   â”œâ”€â”€ transformer.py
 â”‚   â”œâ”€â”€ position_encoding.py
 â”œâ”€â”€ utils/                # matcher, loss, evaluation
 â”‚   â”œâ”€â”€ matcher.py
 â”‚   â”œâ”€â”€ loss.py
 â”‚   â”œâ”€â”€ eval_utils.py
 â”œâ”€â”€ train.py              # training script
 â”œâ”€â”€ eval.py               # mAP evaluation
 â”œâ”€â”€ logs/                 # training_log.csv
 â”œâ”€â”€ checkpoints/          # model checkpoints

```

---

## ğŸ“¦ Dataset Format

The model expects a **COCO-like JSON**, but simplified.  
Each entry should contain:

```json
{
  "image_path": "data/voc/JPEGImages/000001.jpg",
  "boxes": [[xmin, ymin, xmax, ymax], ...],
  "labels": [int, int, ...]
}
```

Bounding boxes must be **absolute pixel coordinates** (they will be normalized internally).

You can easily preprocess VOC, COCO, or your own dataset to this format.

--------

## ğŸš€ Quickstart

### 1. Install dependencies

```bash
pip install torch torchvision tqdm
```

### 2. Prepare dataset

Place your `*.json` file under `data/processed/your_file.json`.

### 3. Train

```bash
python train.py
```

- Supports **training log**, **checkpoint saving**, **tqdm progress bar**

You can modify configs directly in `train.py`:

```python
num_epochs = 100
batch_size = 8
base_lr = 1e-4
backbone_lr = 5e-6
```

### 4. Evaluate

```bash
python eval.py
```

- Uses training set as validation (if no val split is provided)
- Outputs **per-class AP** and **mean AP**

------

## ğŸ›  Features Implemented

| Feature                              | Status |
| ------------------------------------ | ------ |
| ResNet-50 Backbone (Frozen/Unfrozen) | âœ…      |
| Sinusoidal Position Encoding         | âœ…      |
| Transformer Encoder + Decoder        | âœ…      |
| Object Queries                       | âœ…      |
| Set Prediction Loss (Hungarian)      | âœ…      |
| CrossEntropy + L1 + GIoU Loss        | âœ…      |
| Training Log CSV                     | âœ…      |
| Checkpoint Save (Best + Last)        | âœ…      |
| Learning Rate Warmup                 | âœ…      |
| Different LR for backbone            | âœ…      |
| mAP Evaluation (IoU â‰¥ 0.5)           | âœ…      |

------

## ğŸ§ª Notes

- The project is designed to **fit in 8GB GPU memory**
- Input image is resized to 320Ã—320 during training & evaluation
- You can **freeze backbone** in early epochs and unfreeze later
- **mAP is computed only with PyTorch/NumPy** â€” no COCO APIs

------

## ğŸ“˜ References

- [DETR Paper (Facebook AI)](https://arxiv.org/abs/2005.12872)
- [Official DETR Repo](https://github.com/facebookresearch/detectron2)
- [A guide to Object Detection mAP](https://github.com/rafaelpadilla/Object-Detection-Metrics)

------

## ğŸ§‘â€ğŸ’» Author

This project is a personal implementation by a graduate student exploring vision-language models.
 Feel free to fork, modify, or contribute!

> ğŸ“« Feedback or issue reports are welcome via GitHub Issues.

------

